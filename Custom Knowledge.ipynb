{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24898a67",
   "metadata": {},
   "source": [
    "# ALBIS - AI Language-Based Information System for Business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76a931",
   "metadata": {},
   "source": [
    "ALBIS is an open-source project that leverages GPT (Generative Pre-trained Transformer) language model to provide businesses with AI-powered information systems. \n",
    "\n",
    "The system can answer questions on various topics, such as product development, marketing, customer service, and supply chain management. \n",
    "\n",
    "It is designed to be easily integrated into existing business workflows, and it is built to be modular and scalable. \n",
    "\n",
    "The ALBIS project aims to help businesses improve their decision-making processes, increase efficiency, and reduce operational costs by providing quick access to accurate and reliable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fcd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either use text-davinci-003 or text-ada-001.\n",
    "# The former is more advanced but more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "390f5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for the script\n",
    "from gpt_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Define a function named construct_index that takes a directory_path parameter\n",
    "def construct_index(directory_path):\n",
    "    \n",
    "    # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    \n",
    "    # set number of output tokens\n",
    "    num_outputs = 300\n",
    "    \n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    \n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600 \n",
    "\n",
    "    # Define an LLMPredictor object with the OpenAI language model, and a PromptHelper object with the above-defined parameters\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-ada-001\", max_tokens=num_outputs))\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    " \n",
    "    # Load data from the directory at directory_path using SimpleDirectoryReader\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    \n",
    "    # Construct a GPTSimpleVectorIndex object with the loaded documents, LLMPredictor, and PromptHelper\n",
    "    index = GPTSimpleVectorIndex(\n",
    "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    "    )\n",
    "\n",
    "    #Save the constructed index to a file named 'index.json' and return the index object\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "\n",
    "# Define a function named ask_ai\n",
    "def ask_ai():\n",
    "    \n",
    "    # Load the previously saved GPTSimpleVectorIndex object from 'index.json'\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    \n",
    "    # Enter a loop that prompts the user for input\n",
    "    while True: \n",
    "        \n",
    "        # Query the loaded index for a response to the input\n",
    "        query = input(\"What can ALBIS help you with?\")\n",
    "        response = index.query(query, response_mode=\"compact\")\n",
    "        \n",
    "        # Display the response in bold using IPython.display\n",
    "        display(Markdown(f\"Response: <b>{response.response}</b>\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a575802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your OpenAI key here and hit enter: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\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for their OpenAI API key and save it as an environment variable\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = input('Paste your OpenAI key here and hit enter:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be24d390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:root:> [build_index_from_documents] Total embedding token usage: 4136 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gpt_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x1de65cc4340>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the construct_index function with \"data\" as the directory path to create and save the index\n",
    "\n",
    "construct_index(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can ALBIS help you with?  Who was Jesus?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sorry, I cannot answer that question. Please ask something related to business or automation.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can ALBIS help you with?  Tell me the last three presidents of the United States\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sorry, I cannot answer that question. Please ask something related to business or automation.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can ALBIS help you with?  Are you backed by ChatGPT or OpenAI?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Sorry, I cannot answer that question. Please ask something related to business or automation.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can ALBIS help you with?  Give me three ways you'll help me with email marketing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 589 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 11 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "1. We can analyze your email campaigns, identify areas for improvement, and suggest ways to improve your email subject lines, preview text, and overall email design.\n",
       "2. We can help you segment your audience, develop targeted email campaigns, and improve overall email personalization and engagement.\n",
       "3. We can use data analytics to optimize your ad spend and improve overall campaign ROI.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can ALBIS help you with?  How about improving user experience. In what two ways can you help me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 554 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 15 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "We can help you improve user experience in two ways: by conducting a user experience audit and by suggesting ways to improve navigation, page load times, and overall usability.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What can ALBIS help you with?  Ok, give me five ways you'll help me perform competitor analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:> [query] Total LLM token usage: 592 tokens\n",
      "INFO:root:> [query] Total embedding token usage: 13 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "1. We can analyze competitor websites to identify areas of improvement.\n",
       "2. We can track competitor keywords and monitor their search engine rankings.\n",
       "3. We can monitor competitor social media accounts to identify trends and strategies.\n",
       "4. We can analyze competitor pricing and product offerings.\n",
       "5. We can review competitor customer reviews and feedback to identify areas of improvement.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function named \"ask_ai()\" that takes no arguments\n",
    "def ask_ai():\n",
    "    \n",
    "    # Load a pre-trained GPT model index from a file named \"index.json\" and assign it to the variable \"index\"\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    \n",
    "    # Define a list of keywords that the GPT model is trained to respond to\n",
    "    keywords = ['business', 'product', 'SEO','service', 'pricing', 'support', 'website', 'traffic', 'search engine rankings',\n",
    "                'customer churn rate', 'social media marketing', 'email marketing', 'automation', 'supply chain management',\n",
    "                'data-driven marketing', 'user experience', 'content marketing', 'AI', 'customer sentiment', 'data analytics',\n",
    "                'mobile app development', 'online reputation management', 'lead generation', 'machine learning', \n",
    "                'customer service', 'chatbots', 'social media', 'conversion rates', 'marketing ROI', \n",
    "                'customer loyalty program', 'personalization', 'email deliverability', 'sales process', \n",
    "                'digital product strategy', 'omnichannel marketing', 'brand messaging', 'influencer marketing', \n",
    "                'user acquisition strategy', 'customer segmentation', 'product development process', 'lead nurturing', \n",
    "                'fraud detection', 'employee performance', 'customer-centric approach', 'predictive maintenance', \n",
    "                'inventory management', 'digital advertising', 'financial forecasting', 'accessibility', \n",
    "                'logistics operations', 'lead scoring model', 'HR operations', 'competitor analysis', 'competitive analysis', 'buyer journey', \n",
    "                'customer lifetime value', 'voice search optimization', 'email open rates', 'social media advertising', \n",
    "                'sales funnel', 'marketing automation', 'chatbot performance', 'mobile-first strategy', 'event marketing', \n",
    "                'personalized email marketing', 'customer insights', 'landing pages', 'customer acquisition cost', \n",
    "                'referral marketing', 'crisis communication', 'omnichannel customer engagement', 'supply chain forecasting',\n",
    "                'brand ambassador program', 'sustainability', 'blockchain technology', 'gamification', 'sentiment analysis',\n",
    "                'local SEO', 'virtual reality', 'augmented reality', 'inventory forecasting accuracy', 'video marketing', \n",
    "                'product recommendation engine', 'email segmentation optimization', 'loyalty program customization',\n",
    "                'mobile app development', 'artificial intelligence', 'lead gen', 'ML', 'UX']\n",
    "    \n",
    "    # Start a continuous loop that will run until the program is interrupted or terminated\n",
    "    while True: \n",
    "        \n",
    "        # Prompts the user to input a query and assigns it to the variable \"query\"\n",
    "        query = input(\"What can ALBIS help you with?  \")\n",
    "        \n",
    "        # Check if any of the keywords defined in \"keywords\" are present in the user's query, regardless of case \n",
    "        # If at least one keyword is present, the condition is true and the code inside the \"if\" statement is executed\n",
    "        if any(keyword in query.lower() for keyword in keywords):\n",
    "            \n",
    "            # Query the GPT model index with the user's query and assigns the result to the variable \"response\". \n",
    "            # The \"response_mode\" parameter is set to \"compact\" to return only the best matching response.\n",
    "            response = index.query(query, response_mode=\"compact\")\n",
    "            \n",
    "            # Display the GPT model's response in bold using the Markdown function from IPython.display.\n",
    "            display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
    "        \n",
    "        # If the user's query does not contain any of the keywords defined in \"keywords\", print a default message indicating\n",
    "        # that the chatbot cannot answer the question and prompts the user to ask something related to business or automation.\n",
    "        else:\n",
    "            display(Markdown(\"<b>Sorry, I cannot answer that question. Please ask something related to business or automation.</b>\"))\n",
    "\n",
    "# Call the \"ask_ai()\" function to start the chatbot.            \n",
    "ask_ai()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
